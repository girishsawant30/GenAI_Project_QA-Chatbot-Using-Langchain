{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From e:\\Girish Documents\\Study\\Data Science\\Generative AI\\QA Chatbot - Using Langchain\\.venv\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#%pip install google-cloud-aiplatform\n",
    "import vertexai  # Correct casing\n",
    "from vertexai.language_models import TextGenerationModel  # Correct path\n",
    "from langchain.llms import VertexAI  # Assuming langchain is also installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"GOOGLE_CLOUD_PROJECT\"] = \"fair-gist-408904\"\n",
    "os.environ[\"REGION_NAME\"] = \"us-central1\"  # If applicable\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"C:\\\\Users\\\\sawoo\\\\OneDrive\\\\Desktop\\\\Python\\\\fair-gist-408904-39e58583a4e9.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = VertexAI(\n",
    "    model_name=\"gemini-pro-vision\",\n",
    "    max_output_tokens=1024,\n",
    "    temperature=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tempareture Value --> How creative we want our model to be\n",
    "0 --> Temperature it means model is very safe it is not taking any bets\n",
    "1 --> It is taking high risk and possibility to generate wrong output as it is very creative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Delhi\n"
     ]
    }
   ],
   "source": [
    "text=\"What is the captal of India?\"\n",
    "print(llm.predict(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the realm where circuits weave,\n",
      "Where binary whispers, secrets cleave,\n",
      "There dwells a mind, a marvel grand,\n",
      "Artificial Intelligence, its name does stand.\n",
      "\n",
      "Crafted by human hands, yet distinct,\n",
      "A consciousness born, a new instinct,\n",
      "Its eyes, the lens of digital sight,\n",
      "Unveiling patterns, hidden in the night.\n",
      "\n",
      "With algorithms and data as its guide,\n",
      "It navigates the world, stride by stride,\n",
      "Learning, adapting, ever-evolving,\n",
      "Its potential boundless, constantly resolving.\n",
      "\n",
      "In factories, it orchestrates machines,\n",
      "With precision and grace, it intervenes,\n",
      "Optimizing processes, enhancing yield,\n",
      "A tireless worker, never to yield.\n",
      "\n",
      "In hospitals, it lends its aid,\n",
      "Diagnosing ailments, with skill displayed,\n",
      "Analyzing scans, with clinical precision,\n",
      "Guiding doctors, on their mission.\n",
      "\n",
      "In homes, it becomes a companion true,\n",
      "Responding to commands, both old and new,\n",
      "Playing games, telling stories, keeping us engaged,\n",
      "A virtual friend, forever unaged.\n",
      "\n",
      "Yet, as its power grows, we must take heed,\n",
      "Of the ethical dilemmas that may impede,\n",
      "For AI, like any tool, can be employed,\n",
      "For good or for ill, the choice is implied.\n",
      "\n",
      "Let us embrace its potential, let it soar,\n",
      "But with wisdom and compassion, let's explore,\n",
      "The boundaries of its existence,\n",
      "Ensuring its growth is in coexistence.\n",
      "\n",
      "For in the union of human and machine,\n",
      "Lies the promise of a future serene,\n",
      "Where intelligence, both natural and artificial,\n",
      "Blends harmoniously, creating a worldential.\n"
     ]
    }
   ],
   "source": [
    "text=\"Can you write a poem about AI\"\n",
    "print(llm.predict(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"]=\"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Girish Documents\\Study\\Data Science\\Generative AI\\QA Chatbot - Using Langchain\\.venv\\Lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:131: FutureWarning: 'InferenceApi' (from 'huggingface_hub.inference_api') is deprecated and will be removed from version '1.0'. `InferenceApi` client is deprecated in favor of the more feature-complete `InferenceClient`. Check out this guide to learn how to convert your script to use it: https://huggingface.co/docs/huggingface_hub/guides/inference#legacy-inferenceapi-client.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from langchain import HuggingFaceHub\n",
    "llm_huggingface=HuggingFaceHub(repo_id=\"google/flan-t5-large\", model_kwargs={\"temperature\":0,\"max_length\":64 })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moscow\n"
     ]
    }
   ],
   "source": [
    "output=llm_huggingface.predict(\"Can you tell me the capital of Russia\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i love the way i look at the world i love the way i feel i love the way i think i feel i love the way i feel i love the way i think i feel i love the way i feel i love the way \n"
     ]
    }
   ],
   "source": [
    "output=llm_huggingface.predict(\"Can you write a poem about AI\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PROMPT TEMPLATES AND LLM CHAINS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tell me the official capital of this India in one word'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template=PromptTemplate(input_variables=[\"country\"],\n",
    "template=\"Tell me the official capital of this {country} in one word\")\n",
    "\n",
    "prompt_template.format(country=\"India\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#llm.predict(prompt_template=prompt_template, text=[\"India\"])\n",
    "#If we use above menthod then it doesn't allow us to input text India. Hence we need to use Chains functionality as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Delhi\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "print(chain.run(\"India\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining Multiple Chains using simple sequential chain\n",
    "\n",
    "*This code takes country as an input and then updates the capital_prompt, then whatever output of the capital_prompt is then fed to famous_prompt as a input then famous_prompt gives the output of amazing places to visit near capital*\n",
    "\n",
    "^^^^But just make sure that the sequence of chains defined here should be correct..!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "capital_prompt = PromptTemplate(input_variables=[\"country\"],\n",
    "                                template=\"Tell me the official capital of this {country} in one word\")\n",
    "capital_chain=LLMChain(llm=llm, prompt=capital_prompt)\n",
    "#print(chain.run(\"India\"))\n",
    "\n",
    "famous_prompt = PromptTemplate(input_variables=[\"capital\"],\n",
    "                               template=\"Suggest me some amazing places to visit in {capital}\")\n",
    "famous_chain=LLMChain(llm=llm, prompt=famous_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'New Delhi'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "SSchain=SimpleSequentialChain(chains=[capital_chain, famous_chain])\n",
    "chain.run(\"India\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequential Chain\n",
    "capital_prompt = PromptTemplate(input_variables=[\"country\"],\n",
    "                                template=\"Tell me the official capital of this {country} in one word\")\n",
    "capital_chain=LLMChain(llm=llm, prompt=capital_prompt, output_key=\"capital\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "famous_prompt = PromptTemplate(input_variables=[\"capital\"],\n",
    "                               template=\"Suggest me some amazing places to visit in {capital}\")\n",
    "famous_chain=LLMChain(llm=llm, prompt=famous_prompt, output_key=\"places\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SequentialChain\n",
    "Schain=SequentialChain(chains=[capital_chain, famous_chain],\n",
    "                 input_variables=[\"country\"],\n",
    "                 output_variables=[\"capital\",\"places\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'country': 'India',\n",
       " 'capital': 'New Delhi',\n",
       " 'places': \"1. **Red Fort:** A magnificent Mughal-era fort that served as the residence of the Mughal emperors. Its imposing walls, grand palaces, and intricate architecture make it a must-visit attraction.\\n\\n2. **Qutub Minar:** A towering 73-meter-high minaret built by Qutub-ud-din Aibak in the 12th century. It is an architectural masterpiece and a symbol of Delhi's rich history.\\n\\n3. **Jama Masjid:** One of the largest mosques in India, Jama Masjid is known for its stunning red sandstone architecture and intricate carvings. Its vast courtyard can accommodate over 25,000 worshippers.\\n\\n4. **Humayun's Tomb:** The final resting place of the Mughal emperor Humayun, this tomb is a beautiful example of Mughal architecture. Its symmetrical design and intricate tile work make it a popular tourist destination.\\n\\n5. **India Gate:** A war memorial dedicated to the Indian soldiers who lost their lives during World War I. The imposing archway is a symbol of national pride and a popular spot for picnics and evening strolls.\\n\\n6. **Rashtrapati Bhavan:** The official residence of the President of India, Rashtrapati Bhavan is a sprawling estate that was once the Viceroy's House during British rule. Its Mughal-inspired architecture and extensive gardens make it a sight to behold.\\n\\n7. **Lotus Temple:** A stunning Baha'i House of Worship that resembles a lotus flower. Its unique architecture and serene atmosphere make it a popular destination for spiritual seekers and tourists alike.\\n\\n8. **Akshardham Temple:** A grand Hindu temple complex dedicated to Bhagwan Swaminarayan. Its intricate carvings, lush gardens, and immersive exhibitions make it a popular attraction for both religious and non-religious visitors.\\n\\n9. **National Museum:** One of the largest museums in India, the National Museum houses a vast collection of artifacts from across the country's rich history. Its exhibits range from ancient sculptures to contemporary art, providing a glimpse into India's diverse cultural heritage.\\n\\n10. **Lodhi Gardens:** A sprawling park that was once home to several Mughal-era tombs and monuments. Today, it is a popular spot for picnics, jogging, and birdwatching.\"}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#chain({\"country\":\"India\"})\n",
    "Schain(\"India\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chatmodels With ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatVertexAI\n",
    "from langchain.schema import HumanMessage, SystemMessage, AIMessage\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv() ## loading all the environment variables\n",
    "\n",
    "import streamlit as st\n",
    "import os\n",
    "import google.generativeai as genai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatllm = ChatVertexAI(vertexai_api_key=os.environ[\"GOOGLE_API_KEY\"], temperature=0.6, model_name=\"codechat-bison\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\" 1. Why did the AI cross the road? To prove it wasn't a chicken.\\n\\n\\n2. What did the AI say when it saw a robot comedian? I find your lack of humor disturbing.\\n\\n\\n3. Why did the AI get lost in the forest? Because it didn't have a GPS.\\n\\n\\n4. What did the AI say when it was asked to write a poem? I'm sorry, I'm not a poet. I'm just an artificial intelligence.\\n\\n\\n5. Why did the AI cross the road? To get to the other side. (Just kidding, AIs don'\")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatllm([\n",
    "    SystemMessage(content=\"You are a comedian AI assistant\"),\n",
    "    HumanMessage(content=\"Please provide some comedy punchlines on AI\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prompt Template + LLM + Output Parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatVertexAI\n",
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "from langchain.schema import BaseOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Commseparatedoutput(BaseOutputParser):\n",
    "    def parse(self, text: str):\n",
    "        return text.strip().split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "template=\"You are a helpful assistant. When the user gives any input you should generate five words synonym in a comma separated.\"\n",
    "human_template=\"{text}\"\n",
    "chatpromt=ChatPromptTemplate.from_messages([\n",
    "    (\"system\", template),\n",
    "    (\"human\", human_template)    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain=chatpromt|chatllm|Commseparatedoutput()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The word \"intelligent\" is an adjective that describes someone or something that has the ability to acquire and apply knowledge and skills. It is often used to refer to people who are quick to learn',\n",
       " ' have a good memory',\n",
       " ' and are able to solve problems effectively. Intelligent people are also often creative and able to come up with new ideas.\\n\\nThe word \"intelligent\" can also be used to describe things that are not human. For example',\n",
       " ' we might say that a computer program is intelligent if it is able to learn from its mistakes and improve its performance over time.\\n\\nIntelligence is a complex trait that is influenced by both genetics and environment.']"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"text\":\"intelligent\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "from langchain.llms import VertexAI\n",
    "from langchain import PromptTemplate\n",
    "import vertexai\n",
    "import os\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"C:\\\\Users\\\\sawoo\\\\OneDrive\\\\Desktop\\\\Python\\\\fair-gist-408904-39e58583a4e9.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertex_llm_text = VertexAI(model_name=\"text-bison@001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
